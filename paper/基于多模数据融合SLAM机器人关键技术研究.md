#                 **基于多模数据融合SLAM机器人关键技术研究**

​																										**摘    要**

SLAM（Simultaneous Localization and Mapping  同步定位与建图）是实现移动机器人自主导航的关键，基于视觉和激光的 SLAM 是两种最常用的方法。基于RGB-D视觉的SLAM被广泛应用于室内场景，虽然RGB-D相机可获取丰富的环境信息，但存在易受日光影响、视野范围狭小、噪声大等缺点，在实际应用中度和鲁棒性较差。同时，传统RGB-D的SLAM 方法未充分考虑冗余视野的滤除，而实际应用中，冗余视野的障碍不会对机器人的实际通行产生影响。另外，常应用于室内服务机器人的二维激光雷达虽然精度较高，抗干扰能力强，但环境信息的获取范围仅局限于一个平面，环境信息获取不完整。基于以上问题，本文提出了一种基于Kinect和二维激光雷达的低成本、精度高、可靠性强的室内建图与定位方法。本文的主要工作内容包括以下几个方面：

（1）对国内外有关 SLAM 的文献做了深入研究，分别就视觉、激光、及多传感器的SLAM框架作了概述，同时提出本文要解决的问题及方法。

（2）基于 ROS 系统搭建了RPLIDAR-A2激光雷达和Kinect相机的多传感器移动机器人平台，建立机器人运动模型和传感器状态估计模型，再引入传统标定法以完成Kinect的RGB镜头和红外镜头的标定，从而获得Kinect的相机参数。

（3）基于Kinect采集影响机器人通行高度范围内的深度图像，通过PCL处理得到与之匹配三维点云，并采用ORB特征点匹配方法得到相机的旋转及平移向量，进而实现点云拼接，再对点云降采样，采用xxx算法对二维栅格占据进行评估，同时根据机器人实际通过能力，滤除地面上可通行高度范围障碍物的影响。 

（4）对于激光雷达，传统（xxx地图）创建方法存在粒子使用多，计算量大的问题，提出改进方案。通过结合激光雷达扫描数据，采用xxx特征点匹配改进建议分布函数和及自适应重采样，大大降低粒子的使用数量和计算量。 
		（5）基于激光雷达和Kinect获取到的二维占据栅格，通过贝叶斯推理的规则完成多源传感器信息的融合实现了地图构建，同时实现了位姿图优化和基于词袋模型的回环检测。

（6）对以上提出或改进的算法在仿真环境及搭建的移动机器人平台上进行实验，就多传感器与单一传感器在建图精度、系统实时性、以及多传感器融合可能新引入的误差等问题做了分析。

## 第一章 绪论

### 1.1 课题背景及意义

#### 1.1.1 课题背景及意义

随着计算机技术和自动控制等学科的进步，移动机器人及相关技术在近几年得到了飞速发展，成为科学技术最前沿的一个领域之一[1]。传感器和环境信息感知技术也在日趋完善，移动机器人在国防和工业生产以及人民生活中得到了广泛应用[2]。机器人在多个领域的应用：

SLAM 技术在陆地、空中、室内、和水下，甚至人体介入等研究中取得了巨大的进步。移动机器人处于未知环境，通过搭载的各类传感器辨识环境[6]，并对所采集的环境信息进行精确描述，确定机器人所在的空间位置，即完成真实环境的建模，这个即时定位与创建地图的过程叫做 SLAM（Simultaneous Localization and Mapping  同步定位与建图）。通常是这样形容 SLAM 的问题：在陌生环境中的任意位置起，机器人开始移动（包括平移和转动），移动的过程中，通过直接或间接的手段得到机器人位姿估计，从而实现环境地图的全局定位[55]。在完成定位之后，可以实现环境地图的构建，从而实现机器人的自主导航及自主定位功能[54]。机器人要想在陌生环境中进行有效的探索，实现自主运行，其关键在于具备同步定位的和建图的能力[7]。依据机器人的定位信息初步构建增量式的地图，在位姿估计中，对出现的累积误差进行位姿优化，再通过回环检测的方法为后端位姿提供更多有效的数据，进而达到最佳的建图与定位效果，以上也可以称为 SLAM 的期望。

当移动机器人所处的环境是复杂多变的，单一传感器在环境信息检测中一般都存在信息获取不够全面和漏检的可能，单一传感器数据关联困难，无法满足复杂环境下定位与建图的要求[2]。如果单一传感器没有足够的鲁棒性和可靠性，传感器失效从导致整个系统失效。相对而言，采用多个传感器同时对环境数据检测然后再进行数据融合是非常有效的方法。多传感器融合对技术要求较高，根据传感器种类不同，分为同质传感器融合和异质传感器融合。实际应用中并非传感器使用的越多越好，不合理的传感器组合不但增加成本，还会发生传感器之间的相互干扰。使用多个传感器同时采集环境特征和状态测量，得到的环境信息融合在一起的过程就是多传感器融合，多传感器融合可使移动机器人更好地了解周边环境。完成多传感器能够融合过程，就要实现多个传感器特征数据关联，然后确定测量的信息是否属于同一特征源信息，将同一特征源信息进行分组再确认漏检发生，从而降低传感器漏检率，提高信息获取精度。目前，为提高自主导航系统建图定位精度和系统的容错能力，采用多传感器组合导航是最行之有效的方法[28]。通过以上综述，多传感器的信息融合具有的好处：

1. 在机器人不同位置安装多个传感器来实现增加观察空间和机器人的感知范围；
2. 通过多个传感器同时或多次观察某个场景，来提高环境信息的可信度；
3. 如果某个传感器发生故障，将不会严重影响系统的运行，提高了系统的可靠性；

SLAM（Simultaneous Localization and Mapping 同步定位与建图）是实现移动机器人自主导航的关键，基于视觉和激光的SLAM是两种最常用的方法。

#### 1.1.2 国内外研究现状

移动机器人的自主导航是指机器人从一个地方自主地运动到另外一个地方，有效地探索未知区域并完成给定任务。这就要求机器人在未知区域内能够确定自身所在环境中的位子，即机器人自定位问题。

移动机器人的 SLAM 研究是机器人领域的热点，常用传感器有激光雷达、IMU、摄像机、超声波传感器等，根据移动机器人搭载传感器类型不同，基于 SLAM 的研究可以分为视觉 SLAM 和激光 SLAM 两大类[4]，分类方法如图 1-2 所示。

## 第二章 SLAM技术概述及ROS系统概述

本章介绍了SLAM技术和ROS系统。首先介绍了SLAM技术的基本框架，并对SLAM每个阶段步骤做了具体的实验。

其次介绍了ROS系统及其基本工具，对使用的机器人平台和传感器建模，包括轮式机器人运动学模型，Kinect 相机和单线激光雷达模型。同时对常用坐标系做了介绍和推导。对于 RGB-D 相机需要完成标定，介绍了标定原理及相机的内外参数获取过程，本章作为后面章节的研究基础。

### 2.1 SLAM技术



#### 2.1.1 SLAM研究现状



#### 2.1.2 SLAM基本框架结构



#### 2.1.3 SLAM各模块技术详述



### 2.2 ROS系统



#### 2.2.1 ROS系统基本概念



#### 2.2.2 ROS系统基本工具



## 第三章 基于视觉传感器的SLAM研究

### 3.1 视觉系统信息获取建模 



### 3.2 RGB-D相机标定



### 3.3 RGB-D相机视觉系统建模



### 3.4 RGB-D相机视觉信息特征提取



### 3.5



## 第四章 基于激光传感器的SLAM研究

### 4.1 激光传感器1



### 4.2 激光传感器2



## 第五章 基于视觉和激光传感器融合的SLAM

### 5.1 融合算法1



### 5.2 融合算法2



## 第六章 实验设计与分析

### 6.1 实验设计平台环境概述



### 6.2 视觉相机标定实验



### 6.3 SLAM建图及实验



## 第七章 结论与展望

### 7.1 论文实验总结



### 7.2 展望



## 参考文献



